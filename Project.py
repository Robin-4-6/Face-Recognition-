# -*- coding: utf-8 -*-
"""Final_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LszK57S-PtVQ4WFvMHLgdQ-ps_X2ufQW

# **01-Install Libraries**:
"""

!pip install deepface

#Installing The Faiss Vector Database
!pip install faiss-cpu

#Installing Gradio, to create simple UI
!pip install gradio

#Importing Libraries
import numpy as np
import pandas as pd
from PIL import Image
from deepface import DeepFace
import matplotlib.pyplot as plt
import torch
import torchvision.transforms as transforms
from sklearn.datasets import fetch_lfw_people
import faiss
import gradio as gr
import io

"""# **02-Load Dataset:**

-----------Loading data from LFW-----------
"""

# Loading LFW dataset
LFW = fetch_lfw_people(min_faces_per_person=40)
faces = LFW.images
labels = LFW.target_names
labels_indices = LFW.target

# Create labels for each face in the dataset (Because we're risking to have one single label attached to each person and not to each picture)
labels_list = [labels[i] for i in labels_indices]

# Check: the number of samples (pictures we have), the dimensions of the pics and the number of ppl we gonna treat
print("Number of pics we have:", faces.shape[0] )
print("Shape of Image:", faces.shape[1:] )
print("Number of people:", labels.shape[0] )

"""-----------Checking on the Dataset by displaying a random face-----------"""

# Generating a random index for a random face
random_num = np.random.randint(0, len(faces))
random_face = faces[random_num]
label = labels[labels_indices[random_num]]
plt.imshow(random_face, cmap='gray')
plt.title(f"Random Face: {label}")
plt.show()

"""# **03-Extract Face Embeddings**

-----------Compute Face Embedding from Image-----------
"""

def get_face_embedding(face_image):
    # Check if the images are Numpy array and convert to PIL Image Format
    if isinstance(face_image, np.ndarray):
        face_image = Image.fromarray(face_image)
    # Ensure image is in RGB Mode
    if face_image.mode != 'RGB':
        face_image = face_image.convert('RGB')
    # Save image temporarely for DeepFace
    temp_image_path = '/tmp/temp_face.jpg'
    face_image.save(temp_image_path)
    # Use FaceNet Model from DeepFace to get embeddings without face detection (face already detected)
    try:
        embeddings = DeepFace.represent(img_path=temp_image_path, model_name='Facenet', enforce_detection=False)
        return embeddings[0]['embedding']
    except Exception as e:
        print(f"Error getting embedding: {e}")
        return None

"""-----------Extract Embeddings for All Faces in the Dataset-----------"""

# Initialize an empty list to store embeddings of each face
embeddings_list = []
for i, face in enumerate(faces):
    # Keep track of how many faces have been processed
    print(f"Processing face {i+1}/{faces.shape[0]}")
    #Convert each face image to PIL format and scale pixel values
    face_image = Image.fromarray((face * 255).astype(np.uint8))
    #Call get_face_embedding (the old function) to get the embedding for each face
    embedding = get_face_embedding(face_image)
    if embedding is not None:
        embeddings_list.append(embedding)
    else:
        print(f"Failed to get embedding for face {i+1}")

"""# **04-Store the Embeddings in a Vector Store**

-----------Convert the list of embeddings to a NumPy array and save-----------
"""

# Convert the embeddings to Numpy Array
embeddings_array = np.array(embeddings_list)
# Save embeddings and labels to a file
np.save('face_embeddings.npy', embeddings_array)
np.save('face_labels.npy', np.array(labels_list))
# Check if the embeddings and labels have been successfully saved
print(f"Embeddings saved to 'face_embeddings.npy'. Shape: {embeddings_array.shape}")
print(f"Labels saved to 'face_labels.npy'.")

"""-----------Setup FAISS Index-----------"""

# Load embeddings and labels
embeddings = np.load('face_embeddings.npy')
labels = np.load('face_labels.npy')

# Initialize FAISS index
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
# Add embeddings to the index to find the most similar embedding when needed
index.add(embeddings)

# Check if the number of embeddings matches the plan
print("Number of embeddings in the index:", index.ntotal)

# Save and load the FAISS index
faiss.write_index(index, 'faiss_index.bin')
index = faiss.read_index('faiss_index.bin')

print("FAISS index saved and loaded successfully.")

"""-----------Function to Recignize face-----------"""

def recognize_face(image):
    try:
        # Call the face embedding function and check if it generates it successfully
        embedding = get_face_embedding(image)
        if embedding is None:
            return "Failed to get embedding"
        # Convert the embedding to a fitting Format for FAISS
        embedding_array = np.array(embedding).astype('float32')
        # Find the closest match for the FAISS Index
        D, I = index.search(np.expand_dims(embedding_array, axis=0), k=1)
        closest_index = I[0][0]

        # Check if the index is out of bounds
        if closest_index >= len(labels):
            return "Index out of bounds"
        # Return the name of the closest pic along with the Distance
        closest_name = labels[closest_index]
        return f"This face resembles someone from our famous list! Here is the top match: {closest_name}"
    except Exception as e:
        return f"An error occurred: {e}"

# Save embeddings and labels
np.save('face_embeddings.npy', embeddings_array)
np.save('labels.npy', labels)
print(f"Embeddings and labels saved.")

"""# **05-Build a UI for Image Upload**

In this section, you can upload any image, and the system will analyze the face to find its closest match from a list of famous individuals.

The program compares facial features and returns the person it resembles most, along with a similarity score.

Feel free to upload any face! and see how closely it matches one of the well-known figures listed below:

-----------**Getting Names of People in the Dataset**-----------
"""

print(f"Labels : {labels}")

# Create Gradio interface
iface = gr.Interface(
    fn=recognize_face,
    inputs=gr.Image(type="pil"),
    outputs="text",
    title="Face Recognition",
    theme = gr.themes.Soft(
    primary_hue="pink",
    secondary_hue="rose",),
    description="Upload your image here and letâ€™s see who you might look like."
)

# Launch the interface
iface.launch()